{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a9b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import scipy.io as sio\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaab00c",
   "metadata": {},
   "source": [
    "## DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df676349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_model():\n",
    "    \"\"\"Build the classifier\n",
    "    :returns: Classifier model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=4096, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001), activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(32, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001), activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fed874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dict(dict2):\n",
    "    \"\"\"Prepare the dictionary of weights to be loaded by the network\n",
    "    :param dict2: Dictionary to format\n",
    "    :returns: The dictionary properly formatted\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    dict = {}\n",
    "    for i in range(len(dict2)):\n",
    "        if str(i) in dict2:\n",
    "            if dict2[str(i)].shape == (0, 0):\n",
    "                dict[str(i)] = dict2[str(i)]\n",
    "            else:\n",
    "                weights = dict2[str(i)][0]\n",
    "                weights2 = []\n",
    "                for weight in weights:\n",
    "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
    "                        weights2.append(weight[0])\n",
    "                    else:\n",
    "                        weights2.append(weight)\n",
    "                dict[str(i)] = weights2\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dfc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model, weights_file):\n",
    "    \"\"\"Loads the pretrained weights into the network architecture\n",
    "    :param model: keras model of the network\n",
    "    :param weights_file: Path to the weights file\n",
    "    :returns: The input model with the weights properly loaded\n",
    "    :rtype: keras.model\n",
    "    \"\"\"\n",
    "    dict2 = sio.loadmat(weights_file)\n",
    "    dict = conv_dict(dict2)\n",
    "    i = 0\n",
    "    for layer in model.layers:\n",
    "        weights = dict[str(i)]\n",
    "        layer.set_weights(weights)\n",
    "        i += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ec1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier and load pretrained weights\n",
    "def create_classifier_model():\n",
    "    model = classifier_model()\n",
    "    model = load_weights(model, './weights_L1L2.mat')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f155ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,114,113\n",
      "Trainable params: 2,114,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_classifier_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f7384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=20 took: 0:00:15.344571, loss: 30.762760162353516\n",
      "Iteration=40 took: 0:00:21.867407, loss: 30.48362159729004\n",
      "Iteration=60 took: 0:00:28.518407, loss: 30.23193359375\n",
      "Iteration=80 took: 0:00:35.112095, loss: 29.88795280456543\n",
      "Iteration=100 took: 0:00:41.823448, loss: 29.361705780029297\n",
      "Iteration=120 took: 0:00:48.188143, loss: 29.60045051574707\n",
      "Iteration=140 took: 0:00:54.680323, loss: 28.552034378051758\n",
      "Iteration=160 took: 0:01:01.355970, loss: 28.53481101989746\n",
      "Iteration=180 took: 0:01:07.887586, loss: 28.373279571533203\n",
      "Iteration=200 took: 0:01:14.380443, loss: 27.12131118774414\n",
      "Iteration=220 took: 0:01:20.870370, loss: 26.861955642700195\n",
      "Iteration=240 took: 0:01:26.915887, loss: 26.70330810546875\n",
      "Iteration=260 took: 0:01:33.410127, loss: 26.57275390625\n",
      "Iteration=280 took: 0:01:39.675758, loss: 26.969945907592773\n",
      "Iteration=300 took: 0:01:46.108856, loss: 25.599271774291992\n",
      "Iteration=320 took: 0:01:52.531627, loss: 26.429174423217773\n",
      "Iteration=340 took: 0:01:58.756344, loss: 25.234088897705078\n",
      "Iteration=360 took: 0:02:05.236363, loss: 25.78542137145996\n",
      "Iteration=380 took: 0:02:11.613833, loss: 24.152387619018555\n",
      "Iteration=400 took: 0:02:17.751339, loss: 24.499961853027344\n",
      "Iteration=420 took: 0:02:24.256522, loss: 23.002412796020508\n",
      "Iteration=440 took: 0:02:30.642346, loss: 23.770822525024414\n",
      "Iteration=460 took: 0:02:37.362145, loss: 24.024152755737305\n",
      "Iteration=480 took: 0:02:44.152640, loss: 22.69675636291504\n",
      "Iteration=500 took: 0:02:51.026398, loss: 21.104387283325195\n",
      "Iteration=520 took: 0:02:57.546770, loss: 23.69797134399414\n",
      "Iteration=540 took: 0:03:04.067076, loss: 22.676843643188477\n",
      "Iteration=560 took: 0:03:10.490788, loss: 20.410634994506836\n",
      "Iteration=580 took: 0:03:17.140527, loss: 21.638389587402344\n",
      "Iteration=600 took: 0:03:23.673063, loss: 22.01326560974121\n",
      "Iteration=620 took: 0:03:30.060429, loss: 20.110139846801758\n",
      "Iteration=640 took: 0:03:36.277253, loss: 21.27778434753418\n",
      "Iteration=660 took: 0:03:42.855655, loss: 22.395719528198242\n",
      "Iteration=680 took: 0:03:49.499624, loss: 21.64043426513672\n",
      "Iteration=700 took: 0:03:56.019204, loss: 22.285520553588867\n",
      "Iteration=720 took: 0:04:02.745410, loss: 18.92748260498047\n",
      "Iteration=740 took: 0:04:08.952017, loss: 23.570201873779297\n",
      "Iteration=760 took: 0:04:15.491988, loss: 21.10755729675293\n",
      "Iteration=780 took: 0:04:21.864635, loss: 20.644392013549805\n",
      "Iteration=800 took: 0:04:28.314217, loss: 22.273115158081055\n",
      "Iteration=820 took: 0:04:34.546127, loss: 21.365278244018555\n",
      "Iteration=840 took: 0:04:41.006899, loss: 21.545438766479492\n",
      "Iteration=860 took: 0:04:47.360811, loss: 20.34792709350586\n",
      "Iteration=880 took: 0:04:53.862990, loss: 19.67926597595215\n",
      "Iteration=900 took: 0:05:00.235429, loss: 20.12604331970215\n",
      "Iteration=920 took: 0:05:06.701170, loss: 19.294790267944336\n",
      "Iteration=940 took: 0:05:12.882194, loss: 18.174325942993164\n",
      "Iteration=960 took: 0:05:19.042248, loss: 19.432374954223633\n",
      "Iteration=980 took: 0:05:25.756697, loss: 18.1103572845459\n",
      "Iteration=1000 took: 0:05:32.056306, loss: 17.153034210205078\n",
      "Iteration=1020 took: 0:05:38.818578, loss: 16.692317962646484\n",
      "Iteration=1040 took: 0:05:45.366809, loss: 19.081607818603516\n",
      "Iteration=1060 took: 0:05:51.917888, loss: 16.676700592041016\n",
      "Iteration=1080 took: 0:05:58.669798, loss: 16.43819236755371\n",
      "Iteration=1100 took: 0:06:05.065760, loss: 17.477684020996094\n",
      "Iteration=1120 took: 0:06:11.197141, loss: 19.017240524291992\n",
      "Iteration=1140 took: 0:06:17.553710, loss: 17.15904426574707\n",
      "Iteration=1160 took: 0:06:24.057381, loss: 15.067122459411621\n",
      "Iteration=1180 took: 0:06:30.369548, loss: 17.205129623413086\n",
      "Iteration=1200 took: 0:06:37.156902, loss: 17.089956283569336\n",
      "Iteration=1220 took: 0:06:43.593366, loss: 18.331024169921875\n",
      "Iteration=1240 took: 0:06:49.970413, loss: 14.944867134094238\n",
      "Iteration=1260 took: 0:06:56.352684, loss: 17.642152786254883\n",
      "Iteration=1280 took: 0:07:02.531846, loss: 18.131317138671875\n",
      "Iteration=1300 took: 0:07:08.625596, loss: 18.224035263061523\n",
      "Iteration=1320 took: 0:07:14.991167, loss: 16.88178062438965\n",
      "Iteration=1340 took: 0:07:21.617920, loss: 15.469284057617188\n",
      "Iteration=1360 took: 0:07:28.250386, loss: 14.425209999084473\n",
      "Iteration=1380 took: 0:07:34.651293, loss: 18.722108840942383\n",
      "Iteration=1400 took: 0:07:41.119395, loss: 17.08812141418457\n",
      "Iteration=1420 took: 0:07:47.446949, loss: 12.693180084228516\n",
      "Iteration=1440 took: 0:07:53.781714, loss: 15.422110557556152\n",
      "Iteration=1460 took: 0:08:00.522574, loss: 12.344046592712402\n",
      "Iteration=1480 took: 0:08:07.192857, loss: 13.43293571472168\n",
      "Iteration=1500 took: 0:08:13.507473, loss: 16.933944702148438\n",
      "Iteration=1520 took: 0:08:19.978451, loss: 11.309017181396484\n",
      "Iteration=1540 took: 0:08:26.294075, loss: 16.274572372436523\n",
      "Iteration=1560 took: 0:08:32.586989, loss: 20.3327693939209\n",
      "Iteration=1580 took: 0:08:38.705762, loss: 15.121634483337402\n",
      "Iteration=1600 took: 0:08:45.161284, loss: 15.078274726867676\n",
      "Iteration=1620 took: 0:08:51.525536, loss: 14.856748580932617\n",
      "Iteration=1640 took: 0:08:57.920846, loss: 11.224031448364258\n",
      "Iteration=1660 took: 0:09:04.675807, loss: 16.24217987060547\n",
      "Iteration=1680 took: 0:09:10.834067, loss: 13.181337356567383\n",
      "Iteration=1700 took: 0:09:17.370517, loss: 13.785518646240234\n",
      "Iteration=1720 took: 0:09:23.417443, loss: 13.13228702545166\n",
      "Iteration=1740 took: 0:09:29.826265, loss: 11.850053787231445\n",
      "Iteration=1760 took: 0:09:36.167924, loss: 12.697760581970215\n",
      "Iteration=1780 took: 0:09:42.513204, loss: 10.643338203430176\n",
      "Iteration=1800 took: 0:09:48.922040, loss: 13.232128143310547\n",
      "Iteration=1820 took: 0:09:55.192220, loss: 11.42048454284668\n",
      "Iteration=1840 took: 0:10:01.846928, loss: 12.599705696105957\n",
      "Iteration=1860 took: 0:10:08.299225, loss: 12.29300594329834\n",
      "Iteration=1880 took: 0:10:14.606300, loss: 15.759587287902832\n",
      "Iteration=1900 took: 0:10:21.054414, loss: 13.667532920837402\n",
      "Iteration=1920 took: 0:10:27.706117, loss: 14.06458568572998\n",
      "Iteration=1940 took: 0:10:34.174833, loss: 12.762563705444336\n",
      "Iteration=1960 took: 0:10:40.925947, loss: 13.85787582397461\n",
      "Iteration=1980 took: 0:10:47.149055, loss: 10.814740180969238\n",
      "Iteration=2000 took: 0:10:53.562437, loss: 15.56730842590332\n",
      "Iteration=2020 took: 0:10:59.952041, loss: 12.241924285888672\n",
      "Iteration=2040 took: 0:11:06.641354, loss: 11.605783462524414\n",
      "Iteration=2060 took: 0:11:12.966763, loss: 11.715581893920898\n",
      "Iteration=2080 took: 0:11:19.575440, loss: 11.883475303649902\n",
      "Iteration=2100 took: 0:11:25.804428, loss: 10.289166450500488\n",
      "Iteration=2120 took: 0:11:32.182651, loss: 14.496207237243652\n",
      "Iteration=2140 took: 0:11:38.492235, loss: 10.987838745117188\n",
      "Iteration=2160 took: 0:11:45.317974, loss: 11.881711959838867\n",
      "Iteration=2180 took: 0:11:51.752842, loss: 8.712672233581543\n",
      "Iteration=2200 took: 0:11:57.984992, loss: 12.21516227722168\n",
      "Iteration=2220 took: 0:12:04.401405, loss: 15.251161575317383\n",
      "Iteration=2240 took: 0:12:11.127717, loss: 13.680275917053223\n",
      "Iteration=2260 took: 0:12:17.287705, loss: 11.19340705871582\n",
      "Iteration=2280 took: 0:12:24.063311, loss: 14.264449119567871\n",
      "Iteration=2300 took: 0:12:30.775387, loss: 13.918395042419434\n",
      "Iteration=2320 took: 0:12:36.954126, loss: 14.509142875671387\n",
      "Iteration=2340 took: 0:12:43.457421, loss: 10.751947402954102\n",
      "Iteration=2360 took: 0:12:50.064247, loss: 11.619380950927734\n",
      "Iteration=2380 took: 0:12:56.406003, loss: 11.059186935424805\n",
      "Iteration=2400 took: 0:13:02.539807, loss: 11.366555213928223\n",
      "Iteration=2420 took: 0:13:08.983099, loss: 12.276738166809082\n",
      "Iteration=2440 took: 0:13:15.297188, loss: 16.11734962463379\n",
      "Iteration=2460 took: 0:13:21.524439, loss: 15.600391387939453\n",
      "Iteration=2480 took: 0:13:27.599176, loss: 13.570756912231445\n",
      "Iteration=2500 took: 0:13:33.947555, loss: 14.749215126037598\n",
      "Iteration=2520 took: 0:13:40.296828, loss: 16.269468307495117\n",
      "Iteration=2540 took: 0:13:46.909309, loss: 11.747862815856934\n",
      "Iteration=2560 took: 0:13:53.265804, loss: 13.000580787658691\n",
      "Iteration=2580 took: 0:13:59.892596, loss: 17.586830139160156\n",
      "Iteration=2600 took: 0:14:06.094519, loss: 12.644010543823242\n",
      "Iteration=2620 took: 0:14:12.626546, loss: 11.749407768249512\n",
      "Iteration=2640 took: 0:14:19.052022, loss: 12.217971801757812\n",
      "Iteration=2660 took: 0:14:25.402933, loss: 11.48335075378418\n",
      "Iteration=2680 took: 0:14:31.924413, loss: 9.844138145446777\n",
      "Iteration=2700 took: 0:14:38.434920, loss: 16.6497745513916\n",
      "Iteration=2720 took: 0:14:44.783608, loss: 6.620448112487793\n",
      "Iteration=2740 took: 0:14:51.258940, loss: 9.329620361328125\n",
      "Iteration=2760 took: 0:14:57.688506, loss: 9.352056503295898\n",
      "Iteration=2780 took: 0:15:04.048175, loss: 10.636739730834961\n",
      "Iteration=2800 took: 0:15:10.517608, loss: 10.97836971282959\n",
      "Iteration=2820 took: 0:15:17.089566, loss: 13.664084434509277\n",
      "Iteration=2840 took: 0:15:23.742372, loss: 13.84078598022461\n",
      "Iteration=2860 took: 0:15:29.949876, loss: 9.42189884185791\n",
      "Iteration=2880 took: 0:15:36.167310, loss: 9.159659385681152\n",
      "Iteration=2900 took: 0:15:42.866635, loss: 12.079547882080078\n",
      "Iteration=2920 took: 0:15:49.393453, loss: 11.52783203125\n",
      "Iteration=2940 took: 0:15:55.510407, loss: 11.032922744750977\n",
      "Iteration=2960 took: 0:16:01.972838, loss: 11.296070098876953\n",
      "Iteration=2980 took: 0:16:08.598720, loss: 11.976455688476562\n",
      "Iteration=3000 took: 0:16:15.081195, loss: 6.942850589752197\n",
      "Iteration=3020 took: 0:16:21.741851, loss: 13.592011451721191\n",
      "Iteration=3040 took: 0:16:27.861618, loss: 13.51412296295166\n",
      "Iteration=3060 took: 0:16:33.678412, loss: 9.151833534240723\n",
      "Iteration=3080 took: 0:16:40.059753, loss: 9.047088623046875\n",
      "Iteration=3100 took: 0:16:46.356547, loss: 9.010342597961426\n",
      "Iteration=3120 took: 0:16:52.903380, loss: 9.293206214904785\n",
      "Iteration=3140 took: 0:16:59.627243, loss: 15.795125961303711\n",
      "Iteration=3160 took: 0:17:06.462978, loss: 12.145761489868164\n",
      "Iteration=3180 took: 0:17:12.747779, loss: 11.139779090881348\n",
      "Iteration=3200 took: 0:17:19.365641, loss: 10.349656105041504\n",
      "Iteration=3220 took: 0:17:25.934965, loss: 6.652593612670898\n",
      "Iteration=3240 took: 0:17:32.334641, loss: 11.54774284362793\n",
      "Iteration=3260 took: 0:17:38.760779, loss: 9.83934211730957\n",
      "Iteration=3280 took: 0:17:45.139834, loss: 10.660587310791016\n",
      "Iteration=3300 took: 0:17:51.692999, loss: 11.245388984680176\n",
      "Iteration=3320 took: 0:17:58.262759, loss: 12.865219116210938\n",
      "Iteration=3340 took: 0:18:04.556550, loss: 7.271866798400879\n",
      "Iteration=3360 took: 0:18:10.649725, loss: 14.121235847473145\n",
      "Iteration=3380 took: 0:18:17.311207, loss: 11.509259223937988\n",
      "Iteration=3400 took: 0:18:23.830372, loss: 13.034976959228516\n",
      "Iteration=3420 took: 0:18:30.306822, loss: 10.818406105041504\n",
      "Iteration=3440 took: 0:18:36.917191, loss: 11.010183334350586\n",
      "Iteration=3460 took: 0:18:43.152611, loss: 11.350367546081543\n",
      "Iteration=3480 took: 0:18:49.419717, loss: 9.881697654724121\n",
      "Iteration=3500 took: 0:18:55.715600, loss: 8.432917594909668\n",
      "Iteration=3520 took: 0:19:02.015914, loss: 10.854056358337402\n",
      "Iteration=3540 took: 0:19:08.356760, loss: 10.109572410583496\n",
      "Iteration=3560 took: 0:19:14.588091, loss: 9.126348495483398\n",
      "Iteration=3580 took: 0:19:20.880107, loss: 11.225174903869629\n",
      "Iteration=3600 took: 0:19:27.239337, loss: 9.048699378967285\n",
      "Iteration=3620 took: 0:19:33.735352, loss: 13.421649932861328\n",
      "Iteration=3640 took: 0:19:40.125495, loss: 12.845894813537598\n",
      "Iteration=3660 took: 0:19:46.710179, loss: 12.652191162109375\n",
      "Iteration=3680 took: 0:19:53.308237, loss: 7.986586570739746\n",
      "Iteration=3700 took: 0:19:59.658632, loss: 8.953848838806152\n",
      "Iteration=3720 took: 0:20:05.605570, loss: 11.090723037719727\n",
      "Iteration=3740 took: 0:20:11.768358, loss: 11.350289344787598\n",
      "Iteration=3760 took: 0:20:18.060126, loss: 7.217679977416992\n",
      "Iteration=3780 took: 0:20:24.712775, loss: 9.383527755737305\n",
      "Iteration=3800 took: 0:20:31.214641, loss: 7.912353515625\n",
      "Iteration=3820 took: 0:20:37.378336, loss: 11.649179458618164\n",
      "Iteration=3840 took: 0:20:43.675480, loss: 9.722861289978027\n",
      "Iteration=3860 took: 0:20:49.749927, loss: 7.647562026977539\n",
      "Iteration=3880 took: 0:20:55.969096, loss: 11.280458450317383\n",
      "Iteration=3900 took: 0:21:02.360902, loss: 9.661480903625488\n",
      "Iteration=3920 took: 0:21:08.605261, loss: 9.70591926574707\n",
      "Iteration=3940 took: 0:21:15.096021, loss: 10.327436447143555\n",
      "Iteration=3960 took: 0:21:22.007340, loss: 7.8354902267456055\n",
      "Iteration=3980 took: 0:21:28.757952, loss: 7.22015380859375\n",
      "Iteration=4000 took: 0:21:35.260852, loss: 10.093262672424316\n",
      "Iteration=4020 took: 0:21:41.510264, loss: 13.068584442138672\n",
      "Iteration=4040 took: 0:21:47.856211, loss: 7.513713359832764\n",
      "Iteration=4060 took: 0:21:54.323384, loss: 9.38316822052002\n",
      "Iteration=4080 took: 0:22:00.704540, loss: 12.29710578918457\n",
      "Iteration=4100 took: 0:22:07.113238, loss: 8.293803215026855\n",
      "Iteration=4120 took: 0:22:13.257372, loss: 8.636270523071289\n",
      "Iteration=4140 took: 0:22:19.588696, loss: 12.030497550964355\n",
      "Iteration=4160 took: 0:22:26.051275, loss: 13.542376518249512\n",
      "Iteration=4180 took: 0:22:32.821943, loss: 12.844290733337402\n",
      "Iteration=4200 took: 0:22:39.180018, loss: 9.817103385925293\n",
      "Iteration=4220 took: 0:22:45.398941, loss: 8.134956359863281\n",
      "Iteration=4240 took: 0:22:51.648656, loss: 8.464158058166504\n",
      "Iteration=4260 took: 0:22:58.190047, loss: 12.189101219177246\n",
      "Iteration=4280 took: 0:23:04.473480, loss: 9.491169929504395\n",
      "Iteration=4300 took: 0:23:10.879248, loss: 10.831551551818848\n",
      "Iteration=4320 took: 0:23:17.166171, loss: 8.315152168273926\n",
      "Iteration=4340 took: 0:23:23.562355, loss: 8.991486549377441\n",
      "Iteration=4360 took: 0:23:29.954094, loss: 11.1752290725708\n",
      "Iteration=4380 took: 0:23:36.582135, loss: 7.36227560043335\n",
      "Iteration=4400 took: 0:23:42.820847, loss: 11.35150146484375\n",
      "Iteration=4420 took: 0:23:48.573385, loss: 7.399731636047363\n",
      "Iteration=4440 took: 0:23:54.862488, loss: 10.98917293548584\n",
      "Iteration=4460 took: 0:24:01.220044, loss: 9.8511962890625\n",
      "Iteration=4480 took: 0:24:07.212906, loss: 11.439208984375\n",
      "Iteration=4500 took: 0:24:13.181438, loss: 8.865875244140625\n",
      "Iteration=4520 took: 0:24:19.548550, loss: 11.107137680053711\n",
      "Iteration=4540 took: 0:24:25.851292, loss: 11.027298927307129\n",
      "Iteration=4560 took: 0:24:32.243067, loss: 10.19832706451416\n",
      "Iteration=4580 took: 0:24:38.320535, loss: 12.219277381896973\n",
      "Iteration=4600 took: 0:24:44.608810, loss: 7.70806884765625\n",
      "Iteration=4620 took: 0:24:50.881066, loss: 6.285795211791992\n",
      "Iteration=4640 took: 0:24:57.317580, loss: 8.81559944152832\n",
      "Iteration=4660 took: 0:25:03.636301, loss: 7.690465927124023\n",
      "Iteration=4680 took: 0:25:10.133630, loss: 9.525569915771484\n",
      "Iteration=4700 took: 0:25:16.609642, loss: 9.720393180847168\n",
      "Iteration=4720 took: 0:25:22.689372, loss: 11.62228775024414\n",
      "Iteration=4740 took: 0:25:29.022291, loss: 10.966172218322754\n",
      "Iteration=4760 took: 0:25:35.239562, loss: 9.386775970458984\n",
      "Iteration=4780 took: 0:25:41.947604, loss: 6.850974082946777\n",
      "Iteration=4800 took: 0:25:48.405894, loss: 7.574042320251465\n",
      "Iteration=4820 took: 0:25:54.621786, loss: 9.058369636535645\n",
      "Iteration=4840 took: 0:26:00.473436, loss: 7.825221538543701\n",
      "Iteration=4860 took: 0:26:06.603084, loss: 8.444025993347168\n",
      "Iteration=4880 took: 0:26:12.844337, loss: 12.583155632019043\n",
      "Iteration=4900 took: 0:26:19.109464, loss: 12.359606742858887\n",
      "Iteration=4920 took: 0:26:25.569911, loss: 8.885563850402832\n",
      "Iteration=4940 took: 0:26:32.177515, loss: 6.373403072357178\n",
      "Iteration=4960 took: 0:26:38.429216, loss: 9.212871551513672\n",
      "Iteration=4980 took: 0:26:45.097658, loss: 11.527304649353027\n",
      "Iteration=5000 took: 0:26:51.399139, loss: 9.079154014587402\n",
      "Iteration=5020 took: 0:26:57.546930, loss: 5.819346904754639\n",
      "Iteration=5040 took: 0:27:03.997714, loss: 15.974993705749512\n",
      "Iteration=5060 took: 0:27:10.174701, loss: 8.273679733276367\n",
      "Iteration=5080 took: 0:27:16.616308, loss: 8.428672790527344\n",
      "Iteration=5100 took: 0:27:22.561440, loss: 6.96498441696167\n",
      "Iteration=5120 took: 0:27:28.826826, loss: 5.831005573272705\n",
      "Iteration=5140 took: 0:27:35.257415, loss: 7.493919849395752\n",
      "Iteration=5160 took: 0:27:41.200353, loss: 8.674508094787598\n",
      "Iteration=5180 took: 0:27:47.257654, loss: 11.128467559814453\n",
      "Iteration=5200 took: 0:27:53.868269, loss: 10.162530899047852\n",
      "Iteration=5220 took: 0:28:00.218641, loss: 8.847219467163086\n",
      "Iteration=5240 took: 0:28:06.400880, loss: 6.867639541625977\n",
      "Iteration=5260 took: 0:28:12.573995, loss: 12.764326095581055\n",
      "Iteration=5280 took: 0:28:18.787699, loss: 8.62846851348877\n",
      "Iteration=5300 took: 0:28:25.028816, loss: 6.600423336029053\n",
      "Iteration=5320 took: 0:28:31.416393, loss: 9.844521522521973\n",
      "Iteration=5340 took: 0:28:38.074666, loss: 10.545042037963867\n",
      "Iteration=5360 took: 0:28:44.659414, loss: 10.171530723571777\n",
      "Iteration=5380 took: 0:28:51.005587, loss: 6.657739639282227\n",
      "Iteration=5400 took: 0:28:57.473521, loss: 10.319876670837402\n",
      "Iteration=5420 took: 0:29:03.663991, loss: 8.13948917388916\n",
      "Iteration=5440 took: 0:29:09.789827, loss: 13.994150161743164\n",
      "Iteration=5460 took: 0:29:15.959726, loss: 8.18895149230957\n",
      "Iteration=5480 took: 0:29:22.182049, loss: 6.641483783721924\n",
      "Iteration=5500 took: 0:29:28.621885, loss: 7.731447219848633\n",
      "Iteration=5520 took: 0:29:34.482620, loss: 8.087665557861328\n",
      "Iteration=5540 took: 0:29:40.573974, loss: 8.540335655212402\n",
      "Iteration=5560 took: 0:29:46.976686, loss: 6.496407985687256\n",
      "Iteration=5580 took: 0:29:53.011933, loss: 10.53211498260498\n",
      "Iteration=5600 took: 0:29:59.412189, loss: 12.037457466125488\n",
      "Iteration=5620 took: 0:30:05.627917, loss: 6.148238182067871\n",
      "Iteration=5640 took: 0:30:12.017618, loss: 9.335373878479004\n",
      "Iteration=5660 took: 0:30:18.415969, loss: 9.060064315795898\n",
      "Iteration=5680 took: 0:30:24.851782, loss: 8.216100692749023\n",
      "Iteration=5700 took: 0:30:31.090626, loss: 9.028157234191895\n",
      "Iteration=5720 took: 0:30:37.273354, loss: 6.357545852661133\n",
      "Iteration=5740 took: 0:30:43.441239, loss: 8.981578826904297\n",
      "Iteration=5760 took: 0:30:49.659977, loss: 11.687841415405273\n",
      "Iteration=5780 took: 0:30:55.922318, loss: 9.701497077941895\n",
      "Iteration=5800 took: 0:31:01.703103, loss: 11.681851387023926\n",
      "Iteration=5820 took: 0:31:07.933352, loss: 7.084938049316406\n",
      "Iteration=5840 took: 0:31:14.273366, loss: 8.433096885681152\n",
      "Iteration=5860 took: 0:31:20.421773, loss: 9.645788192749023\n",
      "Iteration=5880 took: 0:31:26.781383, loss: 8.965154647827148\n",
      "Iteration=5900 took: 0:31:33.021335, loss: 10.238762855529785\n",
      "Iteration=5920 took: 0:31:39.396195, loss: 7.830740451812744\n",
      "Iteration=5940 took: 0:31:45.640716, loss: 9.760149002075195\n",
      "Iteration=5960 took: 0:31:51.768483, loss: 10.02577018737793\n",
      "Iteration=5980 took: 0:31:58.243047, loss: 6.007757186889648\n",
      "Iteration=6000 took: 0:32:04.655576, loss: 7.498154163360596\n",
      "Iteration=6020 took: 0:32:10.874745, loss: 8.686482429504395\n",
      "Iteration=6040 took: 0:32:17.244999, loss: 10.012564659118652\n",
      "Iteration=6060 took: 0:32:23.858951, loss: 5.473299026489258\n",
      "Iteration=6080 took: 0:32:30.434937, loss: 9.04513168334961\n",
      "Iteration=6100 took: 0:32:36.555091, loss: 8.122313499450684\n",
      "Iteration=6120 took: 0:32:42.967755, loss: 6.529890537261963\n",
      "Iteration=6140 took: 0:32:49.338492, loss: 9.988215446472168\n",
      "Iteration=6160 took: 0:32:55.865258, loss: 6.764636516571045\n",
      "Iteration=6180 took: 0:33:02.359471, loss: 7.604191303253174\n",
      "Iteration=6200 took: 0:33:08.296595, loss: 4.595827579498291\n",
      "Iteration=6220 took: 0:33:15.020727, loss: 8.70654582977295\n",
      "Iteration=6240 took: 0:33:21.178529, loss: 12.607152938842773\n",
      "Iteration=6260 took: 0:33:27.442690, loss: 9.551850318908691\n",
      "Iteration=6280 took: 0:33:34.067870, loss: 6.936322212219238\n",
      "Iteration=6300 took: 0:33:40.092049, loss: 7.021097183227539\n",
      "Iteration=6320 took: 0:33:46.390629, loss: 7.319508075714111\n",
      "Iteration=6340 took: 0:33:52.969281, loss: 8.96405029296875\n",
      "Iteration=6360 took: 0:33:59.054632, loss: 6.401898384094238\n",
      "Iteration=6380 took: 0:34:05.223153, loss: 6.397923469543457\n",
      "Iteration=6400 took: 0:34:11.323581, loss: 7.120330810546875\n",
      "Iteration=6420 took: 0:34:17.392552, loss: 6.290580749511719\n",
      "Iteration=6440 took: 0:34:23.852320, loss: 9.70273208618164\n",
      "Iteration=6460 took: 0:34:30.344839, loss: 7.7411298751831055\n",
      "Iteration=6480 took: 0:34:36.385810, loss: 7.510490417480469\n",
      "Iteration=6500 took: 0:34:42.760180, loss: 5.828721046447754\n",
      "Iteration=6520 took: 0:34:49.131616, loss: 7.364356517791748\n",
      "Iteration=6540 took: 0:34:55.796864, loss: 8.899663925170898\n",
      "Iteration=6560 took: 0:35:02.290710, loss: 9.91031551361084\n",
      "Iteration=6580 took: 0:35:08.372868, loss: 7.935544967651367\n",
      "Iteration=6600 took: 0:35:14.365625, loss: 9.196167945861816\n",
      "Iteration=6620 took: 0:35:20.623611, loss: 5.948270797729492\n",
      "Iteration=6640 took: 0:35:26.449376, loss: 5.736285209655762\n",
      "Iteration=6660 took: 0:35:32.660600, loss: 10.605428695678711\n",
      "Iteration=6680 took: 0:35:38.913014, loss: 7.000396251678467\n",
      "Iteration=6700 took: 0:35:45.103017, loss: 7.476295471191406\n",
      "Iteration=6720 took: 0:35:51.529512, loss: 7.828344821929932\n",
      "Iteration=6740 took: 0:35:58.063547, loss: 9.618371963500977\n",
      "Iteration=6760 took: 0:36:04.367884, loss: 6.7388458251953125\n",
      "Iteration=6780 took: 0:36:10.753065, loss: 10.868566513061523\n",
      "Iteration=6800 took: 0:36:17.039202, loss: 9.827187538146973\n",
      "Iteration=6820 took: 0:36:23.302398, loss: 6.880699634552002\n",
      "Iteration=6840 took: 0:36:29.729397, loss: 6.208605766296387\n",
      "Iteration=6860 took: 0:36:35.849414, loss: 7.232271194458008\n",
      "Iteration=6880 took: 0:36:41.845559, loss: 8.950582504272461\n",
      "Iteration=6900 took: 0:36:48.263522, loss: 6.593950271606445\n",
      "Iteration=6920 took: 0:36:54.413504, loss: 9.25590991973877\n",
      "Iteration=6940 took: 0:37:00.797908, loss: 7.041944980621338\n",
      "Iteration=6960 took: 0:37:07.108044, loss: 11.390856742858887\n",
      "Iteration=6980 took: 0:37:13.478700, loss: 7.866485118865967\n",
      "Iteration=7000 took: 0:37:19.703152, loss: 9.162331581115723\n",
      "Iteration=7020 took: 0:37:25.825797, loss: 12.070371627807617\n",
      "Iteration=7040 took: 0:37:32.224377, loss: 8.581849098205566\n",
      "Iteration=7060 took: 0:37:38.718485, loss: 5.778477191925049\n",
      "Iteration=7080 took: 0:37:45.063265, loss: 8.325779914855957\n",
      "Iteration=7100 took: 0:37:51.416660, loss: 4.041524410247803\n",
      "Iteration=7120 took: 0:37:57.451407, loss: 5.79919958114624\n",
      "Iteration=7140 took: 0:38:03.678014, loss: 10.408219337463379\n",
      "Iteration=7160 took: 0:38:10.014609, loss: 8.825064659118652\n",
      "Iteration=7180 took: 0:38:16.243079, loss: 7.583967685699463\n",
      "Iteration=7200 took: 0:38:22.590230, loss: 3.9283127784729004\n",
      "Iteration=7220 took: 0:38:28.905626, loss: 10.635095596313477\n",
      "Iteration=7240 took: 0:38:35.136910, loss: 5.599667072296143\n",
      "Iteration=7260 took: 0:38:41.538480, loss: 7.410834312438965\n",
      "Iteration=7280 took: 0:38:47.833170, loss: 5.255824565887451\n",
      "Iteration=7300 took: 0:38:54.290574, loss: 6.204508304595947\n",
      "Iteration=7320 took: 0:38:59.985084, loss: 5.95363187789917\n",
      "Iteration=7340 took: 0:39:06.223072, loss: 6.047019004821777\n",
      "Iteration=7360 took: 0:39:12.672137, loss: 5.719288349151611\n",
      "Iteration=7380 took: 0:39:19.226260, loss: 10.760004997253418\n",
      "Iteration=7400 took: 0:39:25.279575, loss: 8.121384620666504\n",
      "Iteration=7420 took: 0:39:31.595260, loss: 5.683890342712402\n",
      "Iteration=7440 took: 0:39:37.969368, loss: 8.165035247802734\n",
      "Iteration=7460 took: 0:39:44.191682, loss: 7.140808582305908\n",
      "Iteration=7480 took: 0:39:50.559461, loss: 9.401910781860352\n",
      "Iteration=7500 took: 0:39:56.660893, loss: 4.647700786590576\n",
      "Iteration=7520 took: 0:40:02.953832, loss: 4.503647804260254\n",
      "Iteration=7540 took: 0:40:09.179090, loss: 5.204457759857178\n",
      "Iteration=7560 took: 0:40:15.691964, loss: 8.829710006713867\n",
      "Iteration=7580 took: 0:40:22.063770, loss: 5.685511112213135\n",
      "Iteration=7600 took: 0:40:28.237905, loss: 8.020352363586426\n",
      "Iteration=7620 took: 0:40:34.588407, loss: 8.840414047241211\n",
      "Iteration=7640 took: 0:40:40.705037, loss: 8.410861015319824\n",
      "Iteration=7660 took: 0:40:47.155315, loss: 8.199871063232422\n",
      "Iteration=7680 took: 0:40:53.407859, loss: 8.731164932250977\n",
      "Iteration=7700 took: 0:40:59.626473, loss: 8.117086410522461\n",
      "Iteration=7720 took: 0:41:06.067051, loss: 5.832245349884033\n",
      "Iteration=7740 took: 0:41:12.433393, loss: 13.291224479675293\n",
      "Iteration=7760 took: 0:41:18.849623, loss: 6.71185827255249\n",
      "Iteration=7780 took: 0:41:25.047020, loss: 9.273004531860352\n",
      "Iteration=7800 took: 0:41:31.384771, loss: 7.671849250793457\n",
      "Iteration=7820 took: 0:41:37.590134, loss: 5.31989049911499\n",
      "Iteration=7840 took: 0:41:43.865786, loss: 6.60300350189209\n",
      "Iteration=7860 took: 0:41:49.854862, loss: 3.254777669906616\n",
      "Iteration=7880 took: 0:41:56.200465, loss: 8.363946914672852\n",
      "Iteration=7900 took: 0:42:02.164353, loss: 6.912882328033447\n",
      "Iteration=7920 took: 0:42:08.658998, loss: 6.269755840301514\n",
      "Iteration=7940 took: 0:42:14.798643, loss: 8.964295387268066\n",
      "Iteration=7960 took: 0:42:21.067396, loss: 7.8524298667907715\n",
      "Iteration=7980 took: 0:42:27.437398, loss: 6.404389381408691\n",
      "Iteration=8000 took: 0:42:33.679229, loss: 7.862235069274902\n",
      "Iteration=8020 took: 0:42:40.175522, loss: 4.66217041015625\n",
      "Iteration=8040 took: 0:42:46.551364, loss: 6.709121227264404\n",
      "Iteration=8060 took: 0:42:52.818012, loss: 7.570626258850098\n",
      "Iteration=8080 took: 0:42:59.285824, loss: 4.199028491973877\n",
      "Iteration=8100 took: 0:43:05.536613, loss: 5.788783073425293\n",
      "Iteration=8120 took: 0:43:11.302926, loss: 7.812063694000244\n",
      "Iteration=8140 took: 0:43:17.225352, loss: 6.129458904266357\n",
      "Iteration=8160 took: 0:43:23.570671, loss: 7.348825454711914\n",
      "Iteration=8180 took: 0:43:29.718235, loss: 4.6976318359375\n",
      "Iteration=8200 took: 0:43:36.064234, loss: 5.1660637855529785\n",
      "Iteration=8220 took: 0:43:42.072199, loss: 6.399383544921875\n",
      "Iteration=8240 took: 0:43:48.482669, loss: 5.84351110458374\n",
      "Iteration=8260 took: 0:43:54.650641, loss: 10.86275863647461\n",
      "Iteration=8280 took: 0:44:00.359681, loss: 10.535381317138672\n",
      "Iteration=8300 took: 0:44:06.375980, loss: 8.254051208496094\n",
      "Iteration=8320 took: 0:44:12.708747, loss: 7.658790588378906\n",
      "Iteration=8340 took: 0:44:18.940643, loss: 9.059292793273926\n",
      "Iteration=8360 took: 0:44:25.270090, loss: 5.336460590362549\n",
      "Iteration=8380 took: 0:44:31.701125, loss: 5.820870876312256\n",
      "Iteration=8400 took: 0:44:37.822441, loss: 5.432243347167969\n",
      "Iteration=8420 took: 0:44:44.217117, loss: 7.426264762878418\n",
      "Iteration=8440 took: 0:44:50.327827, loss: 9.274897575378418\n",
      "Iteration=8460 took: 0:44:56.505010, loss: 7.854899883270264\n",
      "Iteration=8480 took: 0:45:02.714325, loss: 4.813601016998291\n",
      "Iteration=8500 took: 0:45:08.698076, loss: 4.761331081390381\n",
      "Iteration=8520 took: 0:45:14.777892, loss: 7.117060661315918\n",
      "Iteration=8540 took: 0:45:21.172899, loss: 6.492680549621582\n",
      "Iteration=8560 took: 0:45:27.544412, loss: 7.249945640563965\n",
      "Iteration=8580 took: 0:45:33.879344, loss: 10.284404754638672\n",
      "Iteration=8600 took: 0:45:40.299068, loss: 6.386411190032959\n",
      "Iteration=8620 took: 0:45:46.548310, loss: 2.3412129878997803\n",
      "Iteration=8640 took: 0:45:52.737223, loss: 4.103537082672119\n",
      "Iteration=8660 took: 0:45:59.073931, loss: 6.44602632522583\n",
      "Iteration=8680 took: 0:46:05.263977, loss: 7.272646903991699\n",
      "Iteration=8700 took: 0:46:11.726258, loss: 5.8565449714660645\n",
      "Iteration=8720 took: 0:46:18.056464, loss: 3.9434878826141357\n",
      "Iteration=8740 took: 0:46:24.390543, loss: 5.097653865814209\n",
      "Iteration=8760 took: 0:46:30.561082, loss: 8.252593994140625\n",
      "Iteration=8780 took: 0:46:36.919347, loss: 5.332371234893799\n",
      "Iteration=8800 took: 0:46:42.923302, loss: 5.642529487609863\n",
      "Iteration=8820 took: 0:46:49.115426, loss: 7.501245021820068\n",
      "Iteration=8840 took: 0:46:55.388604, loss: 4.755103588104248\n",
      "Iteration=8860 took: 0:47:02.122516, loss: 5.649996280670166\n",
      "Iteration=8880 took: 0:47:08.301138, loss: 6.158878803253174\n",
      "Iteration=8900 took: 0:47:14.254770, loss: 5.682347774505615\n",
      "Iteration=8920 took: 0:47:20.433319, loss: 4.607488632202148\n",
      "Iteration=8940 took: 0:47:26.632583, loss: 5.349206447601318\n",
      "Iteration=8960 took: 0:47:32.790260, loss: 5.810941696166992\n",
      "Iteration=8980 took: 0:47:39.064099, loss: 9.7985200881958\n",
      "Iteration=9000 took: 0:47:45.431553, loss: 8.879344940185547\n",
      "Iteration=9020 took: 0:47:51.736869, loss: 3.4480910301208496\n",
      "Iteration=9040 took: 0:47:58.099834, loss: 5.694354057312012\n",
      "Iteration=9060 took: 0:48:04.327403, loss: 5.665063858032227\n",
      "Iteration=9080 took: 0:48:10.505652, loss: 6.206631660461426\n",
      "Iteration=9100 took: 0:48:16.639079, loss: 9.550715446472168\n",
      "Iteration=9120 took: 0:48:22.693360, loss: 7.796258926391602\n",
      "Iteration=9140 took: 0:48:28.863860, loss: 6.31338357925415\n",
      "Iteration=9160 took: 0:48:35.401998, loss: 6.467475891113281\n",
      "Iteration=9180 took: 0:48:41.560594, loss: 7.720688343048096\n",
      "Iteration=9200 took: 0:48:47.610763, loss: 7.222262382507324\n",
      "Iteration=9220 took: 0:48:53.798749, loss: 7.078654766082764\n",
      "Iteration=9240 took: 0:49:00.107315, loss: 5.799056529998779\n",
      "Iteration=9260 took: 0:49:06.223494, loss: 6.7759528160095215\n",
      "Iteration=9280 took: 0:49:12.380538, loss: 6.409914970397949\n",
      "Iteration=9300 took: 0:49:18.676164, loss: 7.885736465454102\n",
      "Iteration=9320 took: 0:49:24.813149, loss: 6.639227390289307\n",
      "Iteration=9340 took: 0:49:31.258455, loss: 8.910832405090332\n",
      "Iteration=9360 took: 0:49:37.388236, loss: 4.38921594619751\n",
      "Iteration=9380 took: 0:49:43.640731, loss: 7.418741703033447\n",
      "Iteration=9400 took: 0:49:49.472538, loss: 7.914055824279785\n",
      "Iteration=9420 took: 0:49:55.893227, loss: 5.2909674644470215\n",
      "Iteration=9440 took: 0:50:02.118902, loss: 5.55936336517334\n",
      "Iteration=9460 took: 0:50:08.384108, loss: 6.970143795013428\n",
      "Iteration=9480 took: 0:50:14.410067, loss: 6.971168041229248\n",
      "Iteration=9500 took: 0:50:20.895106, loss: 7.2751851081848145\n",
      "Iteration=9520 took: 0:50:27.323379, loss: 5.48795223236084\n",
      "Iteration=9540 took: 0:50:33.341330, loss: 6.399816989898682\n",
      "Iteration=9560 took: 0:50:39.163654, loss: 5.706791877746582\n",
      "Iteration=9580 took: 0:50:45.428434, loss: 2.5902297496795654\n",
      "Iteration=9600 took: 0:50:51.235791, loss: 6.710803508758545\n",
      "Iteration=9620 took: 0:50:57.520801, loss: 2.546128511428833\n",
      "Iteration=9640 took: 0:51:03.639635, loss: 3.6200685501098633\n",
      "Iteration=9660 took: 0:51:10.000888, loss: 8.753994941711426\n",
      "Iteration=9680 took: 0:51:16.701986, loss: 3.986910820007324\n",
      "Iteration=9700 took: 0:51:23.116367, loss: 6.189768314361572\n",
      "Iteration=9720 took: 0:51:29.552377, loss: 8.982522964477539\n",
      "Iteration=9740 took: 0:51:35.995344, loss: 6.209235668182373\n",
      "Iteration=9760 took: 0:51:42.507360, loss: 6.028176307678223\n",
      "Iteration=9780 took: 0:51:48.441429, loss: 5.996064186096191\n",
      "Iteration=9800 took: 0:51:54.842796, loss: 10.596454620361328\n",
      "Iteration=9820 took: 0:52:00.886294, loss: 6.853697776794434\n",
      "Iteration=9840 took: 0:52:06.797604, loss: 6.311246395111084\n",
      "Iteration=9860 took: 0:52:13.070644, loss: 8.94444751739502\n",
      "Iteration=9880 took: 0:52:19.614217, loss: 4.698908805847168\n",
      "Iteration=9900 took: 0:52:25.620742, loss: 4.489124774932861\n",
      "Iteration=9920 took: 0:52:31.870269, loss: 5.693623065948486\n",
      "Iteration=9940 took: 0:52:38.337467, loss: 4.525055885314941\n",
      "Iteration=9960 took: 0:52:44.693886, loss: 5.314427852630615\n",
      "Iteration=9980 took: 0:52:50.955233, loss: 6.348208904266357\n",
      "Iteration=10000 took: 0:52:57.259304, loss: 8.078110694885254\n",
      "Iteration=10020 took: 0:53:03.546178, loss: 7.929579734802246\n",
      "Iteration=10040 took: 0:53:09.957416, loss: 7.269559860229492\n",
      "Iteration=10060 took: 0:53:16.050537, loss: 6.3194499015808105\n",
      "Iteration=10080 took: 0:53:22.469193, loss: 7.971114158630371\n",
      "Iteration=10100 took: 0:53:28.817536, loss: 7.0537800788879395\n",
      "Iteration=10120 took: 0:53:35.137173, loss: 6.070455551147461\n",
      "Iteration=10140 took: 0:53:41.634175, loss: 7.053041458129883\n",
      "Iteration=10160 took: 0:53:47.798870, loss: 5.690887928009033\n",
      "Iteration=10180 took: 0:53:53.900545, loss: 6.584507465362549\n",
      "Iteration=10200 took: 0:54:00.309808, loss: 4.297520160675049\n",
      "Iteration=10220 took: 0:54:06.631874, loss: 4.680098056793213\n",
      "Iteration=10240 took: 0:54:13.198976, loss: 3.9828944206237793\n",
      "Iteration=10260 took: 0:54:19.326425, loss: 4.49287223815918\n",
      "Iteration=10280 took: 0:54:25.868515, loss: 6.48445987701416\n",
      "Iteration=10300 took: 0:54:32.172141, loss: 6.608421325683594\n",
      "Iteration=10320 took: 0:54:38.476290, loss: 8.302774429321289\n",
      "Iteration=10340 took: 0:54:45.338879, loss: 4.2185282707214355\n",
      "Iteration=10360 took: 0:54:51.538357, loss: 6.801266193389893\n",
      "Iteration=10380 took: 0:54:57.887558, loss: 7.200072765350342\n",
      "Iteration=10400 took: 0:55:04.338682, loss: 5.023535251617432\n",
      "Iteration=10420 took: 0:55:10.446884, loss: 9.063799858093262\n",
      "Iteration=10440 took: 0:55:16.895317, loss: 10.202836036682129\n",
      "Iteration=10460 took: 0:55:23.292555, loss: 5.983341693878174\n",
      "Iteration=10480 took: 0:55:29.414671, loss: 8.06428337097168\n",
      "Iteration=10500 took: 0:55:35.568613, loss: 6.159124851226807\n",
      "Iteration=10520 took: 0:55:41.990526, loss: 3.0279290676116943\n",
      "Iteration=10540 took: 0:55:48.118599, loss: 5.2060723304748535\n",
      "Iteration=10560 took: 0:55:54.075860, loss: 8.690407752990723\n",
      "Iteration=10580 took: 0:56:00.441293, loss: 8.697526931762695\n",
      "Iteration=10600 took: 0:56:06.810993, loss: 4.182478904724121\n",
      "Iteration=10620 took: 0:56:12.994720, loss: 5.9568586349487305\n",
      "Iteration=10640 took: 0:56:19.124870, loss: 5.364045143127441\n",
      "Iteration=10660 took: 0:56:25.043456, loss: 7.6562323570251465\n",
      "Iteration=10680 took: 0:56:31.805121, loss: 7.790465831756592\n",
      "Iteration=10700 took: 0:56:38.077566, loss: 8.5902099609375\n",
      "Iteration=10720 took: 0:56:44.498571, loss: 5.4840922355651855\n",
      "Iteration=10740 took: 0:56:50.757302, loss: 6.276991367340088\n",
      "Iteration=10760 took: 0:56:57.255122, loss: 6.421403408050537\n",
      "Iteration=10780 took: 0:57:03.276675, loss: 6.398197650909424\n",
      "Iteration=10800 took: 0:57:09.345315, loss: 6.393787860870361\n",
      "Iteration=10820 took: 0:57:15.596353, loss: 3.302347421646118\n",
      "Iteration=10840 took: 0:57:22.045292, loss: 5.008842468261719\n",
      "Iteration=10860 took: 0:57:28.322109, loss: 6.5448079109191895\n",
      "Iteration=10880 took: 0:57:34.688063, loss: 4.871348857879639\n",
      "Iteration=10900 took: 0:57:40.841787, loss: 5.312350749969482\n",
      "Iteration=10920 took: 0:57:47.521226, loss: 5.876319885253906\n",
      "Iteration=10940 took: 0:57:54.200648, loss: 4.385084629058838\n",
      "Iteration=10960 took: 0:58:00.142461, loss: 5.666184425354004\n",
      "Iteration=10980 took: 0:58:06.522290, loss: 7.661012649536133\n",
      "Iteration=11000 took: 0:58:12.747600, loss: 5.244572639465332\n",
      "Iteration=11020 took: 0:58:18.843836, loss: 6.121213436126709\n",
      "Iteration=11040 took: 0:58:25.158327, loss: 6.770452499389648\n",
      "Iteration=11060 took: 0:58:31.599586, loss: 5.880482196807861\n",
      "Iteration=11080 took: 0:58:37.814630, loss: 3.8792996406555176\n",
      "Iteration=11100 took: 0:58:44.235679, loss: 7.3856201171875\n",
      "Iteration=11120 took: 0:58:50.395243, loss: 4.6699090003967285\n",
      "Iteration=11140 took: 0:58:56.851901, loss: 4.208285331726074\n",
      "Iteration=11160 took: 0:59:03.110941, loss: 6.2357072830200195\n",
      "Iteration=11180 took: 0:59:09.314579, loss: 4.498418807983398\n",
      "Iteration=11200 took: 0:59:15.438371, loss: 4.515193462371826\n",
      "Iteration=11220 took: 0:59:21.729427, loss: 7.216703414916992\n",
      "Iteration=11240 took: 0:59:28.068311, loss: 6.3080925941467285\n",
      "Iteration=11260 took: 0:59:34.007128, loss: 5.083749294281006\n",
      "Iteration=11280 took: 0:59:40.153518, loss: 6.117691993713379\n",
      "Iteration=11300 took: 0:59:46.529914, loss: 7.4038190841674805\n",
      "Iteration=11320 took: 0:59:52.746105, loss: 4.461027145385742\n",
      "Iteration=11340 took: 0:59:59.070971, loss: 5.0768141746521\n",
      "Iteration=11360 took: 1:00:05.281083, loss: 5.782016277313232\n",
      "Iteration=11380 took: 1:00:11.173876, loss: 4.836007118225098\n",
      "Iteration=11400 took: 1:00:17.358028, loss: 7.0188374519348145\n",
      "Iteration=11420 took: 1:00:23.024142, loss: 4.760701656341553\n",
      "Iteration=11440 took: 1:00:29.192330, loss: 4.438626289367676\n",
      "Iteration=11460 took: 1:00:35.195680, loss: 7.194067478179932\n",
      "Iteration=11480 took: 1:00:41.194871, loss: 6.318074703216553\n",
      "Iteration=11500 took: 1:00:47.571515, loss: 8.889557838439941\n",
      "Iteration=11520 took: 1:00:54.051270, loss: 6.277438163757324\n",
      "Iteration=11540 took: 1:01:00.353825, loss: 4.397378921508789\n",
      "Iteration=11560 took: 1:01:07.077913, loss: 2.9252126216888428\n",
      "Iteration=11580 took: 1:01:13.239714, loss: 5.1037983894348145\n",
      "Iteration=11600 took: 1:01:19.410543, loss: 3.4345862865448\n",
      "Iteration=11620 took: 1:01:25.661952, loss: 4.796737194061279\n",
      "Iteration=11640 took: 1:01:32.132945, loss: 5.324098587036133\n",
      "Iteration=11660 took: 1:01:38.200688, loss: 5.220173358917236\n",
      "Iteration=11680 took: 1:01:44.520086, loss: 4.0237507820129395\n",
      "Iteration=11700 took: 1:01:50.913408, loss: 6.089713096618652\n",
      "Iteration=11720 took: 1:01:57.093932, loss: 5.431095600128174\n",
      "Iteration=11740 took: 1:02:03.369565, loss: 3.245997428894043\n",
      "Iteration=11760 took: 1:02:09.864921, loss: 8.009543418884277\n",
      "Iteration=11780 took: 1:02:16.287808, loss: 5.885669231414795\n",
      "Iteration=11800 took: 1:02:22.439504, loss: 3.6575827598571777\n",
      "Iteration=11820 took: 1:02:28.520697, loss: 5.060828685760498\n",
      "Iteration=11840 took: 1:02:34.924667, loss: 4.080414295196533\n",
      "Iteration=11860 took: 1:02:40.935433, loss: 6.328144550323486\n",
      "Iteration=11880 took: 1:02:47.357230, loss: 3.3632590770721436\n",
      "Iteration=11900 took: 1:02:53.289665, loss: 3.584315538406372\n",
      "Iteration=11920 took: 1:02:59.513628, loss: 6.167668342590332\n",
      "Iteration=11940 took: 1:03:05.577356, loss: 5.641251564025879\n",
      "Iteration=11960 took: 1:03:11.792076, loss: 5.574954032897949\n",
      "Iteration=11980 took: 1:03:18.254234, loss: 2.808359384536743\n",
      "Iteration=12000 took: 1:03:24.428448, loss: 4.067065238952637\n",
      "Iteration=12020 took: 1:03:30.890747, loss: 4.130414962768555\n",
      "Iteration=12040 took: 1:03:37.133253, loss: 5.020940780639648\n",
      "Iteration=12060 took: 1:03:43.176087, loss: 9.892844200134277\n",
      "Iteration=12080 took: 1:03:49.405567, loss: 8.651413917541504\n",
      "Iteration=12100 took: 1:03:55.710442, loss: 6.9572625160217285\n",
      "Iteration=12120 took: 1:04:01.928964, loss: 5.375575542449951\n",
      "Iteration=12140 took: 1:04:08.103684, loss: 3.464324951171875\n",
      "Iteration=12160 took: 1:04:14.122558, loss: 5.812312602996826\n",
      "Iteration=12180 took: 1:04:20.485684, loss: 5.344541549682617\n",
      "Iteration=12200 took: 1:04:26.854155, loss: 5.508588790893555\n",
      "Iteration=12220 took: 1:04:33.093728, loss: 3.872628927230835\n",
      "Iteration=12240 took: 1:04:39.284594, loss: 5.665305137634277\n",
      "Iteration=12260 took: 1:04:45.950773, loss: 5.50179386138916\n",
      "Iteration=12280 took: 1:04:52.113286, loss: 6.33162784576416\n",
      "Iteration=12300 took: 1:04:58.575713, loss: 3.408177614212036\n",
      "Iteration=12320 took: 1:05:04.592503, loss: 7.800000190734863\n",
      "Iteration=12340 took: 1:05:11.064672, loss: 5.087096691131592\n",
      "Iteration=12360 took: 1:05:17.364634, loss: 6.897485256195068\n",
      "Iteration=12380 took: 1:05:23.846147, loss: 4.220521450042725\n",
      "Iteration=12400 took: 1:05:30.156679, loss: 5.912073612213135\n",
      "Iteration=12420 took: 1:05:36.214493, loss: 7.609342575073242\n",
      "Iteration=12440 took: 1:05:42.366845, loss: 10.995538711547852\n",
      "Iteration=12460 took: 1:05:48.663818, loss: 4.864185810089111\n",
      "Iteration=12480 took: 1:05:54.913719, loss: 5.609578609466553\n",
      "Iteration=12500 took: 1:06:01.164965, loss: 9.158920288085938\n",
      "Iteration=12520 took: 1:06:07.516290, loss: 4.028494834899902\n",
      "Iteration=12540 took: 1:06:13.321626, loss: 4.837240695953369\n",
      "Iteration=12560 took: 1:06:19.391753, loss: 7.618656635284424\n",
      "Iteration=12580 took: 1:06:25.804662, loss: 5.929012775421143\n",
      "Iteration=12600 took: 1:06:32.002605, loss: 6.121527671813965\n",
      "Iteration=12620 took: 1:06:37.951723, loss: 7.810277462005615\n",
      "Iteration=12640 took: 1:06:44.033752, loss: 4.437179088592529\n",
      "Iteration=12660 took: 1:06:50.171869, loss: 3.1603288650512695\n",
      "Iteration=12680 took: 1:06:56.131213, loss: 4.279967308044434\n",
      "Iteration=12700 took: 1:07:02.551907, loss: 3.646362781524658\n",
      "Iteration=12720 took: 1:07:08.517030, loss: 7.891392707824707\n",
      "Iteration=12740 took: 1:07:14.732703, loss: 4.082652568817139\n",
      "Iteration=12760 took: 1:07:21.060139, loss: 2.0515549182891846\n",
      "Iteration=12780 took: 1:07:27.511452, loss: 6.936912536621094\n",
      "Iteration=12800 took: 1:07:33.824722, loss: 8.998261451721191\n",
      "Iteration=12820 took: 1:07:39.537742, loss: 4.008744239807129\n",
      "Iteration=12840 took: 1:07:45.844157, loss: 5.532175540924072\n",
      "Iteration=12860 took: 1:07:52.013192, loss: 6.081949710845947\n",
      "Iteration=12880 took: 1:07:58.364327, loss: 3.432115316390991\n",
      "Iteration=12900 took: 1:08:04.055941, loss: 5.6590657234191895\n",
      "Iteration=12920 took: 1:08:10.217031, loss: 2.9525914192199707\n",
      "Iteration=12940 took: 1:08:16.220679, loss: 4.8310136795043945\n",
      "Iteration=12960 took: 1:08:22.607166, loss: 6.574667453765869\n",
      "Iteration=12980 took: 1:08:28.812223, loss: 5.983798027038574\n",
      "Iteration=13000 took: 1:08:34.802640, loss: 5.894076347351074\n",
      "Iteration=13020 took: 1:08:40.738913, loss: 3.811537981033325\n",
      "Iteration=13040 took: 1:08:46.977391, loss: 4.284839153289795\n",
      "Iteration=13060 took: 1:08:53.313251, loss: 4.001704692840576\n",
      "Iteration=13080 took: 1:08:59.723948, loss: 2.5058236122131348\n",
      "Iteration=13100 took: 1:09:05.867866, loss: 6.731678485870361\n",
      "Iteration=13120 took: 1:09:12.137212, loss: 6.313342571258545\n",
      "Iteration=13140 took: 1:09:18.456549, loss: 6.18697452545166\n",
      "Iteration=13160 took: 1:09:25.018382, loss: 7.742317199707031\n",
      "Iteration=13180 took: 1:09:31.098378, loss: 7.372605800628662\n",
      "Iteration=13200 took: 1:09:37.529976, loss: 3.4980382919311523\n",
      "Iteration=13220 took: 1:09:43.732587, loss: 2.7787530422210693\n",
      "Iteration=13240 took: 1:09:49.860392, loss: 4.278576374053955\n",
      "Iteration=13260 took: 1:09:56.268508, loss: 4.467535495758057\n",
      "Iteration=13280 took: 1:10:02.518522, loss: 7.648062705993652\n",
      "Iteration=13300 took: 1:10:08.570144, loss: 4.967088222503662\n",
      "Iteration=13320 took: 1:10:14.988632, loss: 3.6063690185546875\n",
      "Iteration=13340 took: 1:10:21.333067, loss: 5.662055969238281\n",
      "Iteration=13360 took: 1:10:27.746684, loss: 4.568528175354004\n",
      "Iteration=13380 took: 1:10:34.042436, loss: 3.7551510334014893\n",
      "Iteration=13400 took: 1:10:40.674567, loss: 5.818629741668701\n",
      "Iteration=13420 took: 1:10:46.998477, loss: 4.380221843719482\n",
      "Iteration=13440 took: 1:10:53.735737, loss: 3.590395450592041\n",
      "Iteration=13460 took: 1:11:00.424622, loss: 3.6913955211639404\n",
      "Iteration=13480 took: 1:11:06.816001, loss: 5.60744047164917\n",
      "Iteration=13500 took: 1:11:12.940918, loss: 2.237823009490967\n",
      "Iteration=13520 took: 1:11:19.413801, loss: 4.975348949432373\n",
      "Iteration=13540 took: 1:11:25.579144, loss: 6.449720859527588\n",
      "Iteration=13560 took: 1:11:31.865516, loss: 7.34956693649292\n",
      "Iteration=13580 took: 1:11:38.002825, loss: 5.801836967468262\n",
      "Iteration=13600 took: 1:11:44.024697, loss: 3.6887824535369873\n",
      "Iteration=13620 took: 1:11:50.277301, loss: 5.320759296417236\n",
      "Iteration=13640 took: 1:11:56.471175, loss: 3.1767349243164062\n",
      "Iteration=13660 took: 1:12:02.702482, loss: 6.576446056365967\n",
      "Iteration=13680 took: 1:12:09.000608, loss: 4.267762660980225\n",
      "Iteration=13700 took: 1:12:15.160611, loss: 4.845381259918213\n",
      "Iteration=13720 took: 1:12:21.569845, loss: 6.591544151306152\n",
      "Iteration=13740 took: 1:12:27.633096, loss: 6.108394145965576\n",
      "Iteration=13760 took: 1:12:33.771788, loss: 3.1935486793518066\n",
      "Iteration=13780 took: 1:12:40.016486, loss: 6.560000419616699\n",
      "Iteration=13800 took: 1:12:45.870501, loss: 6.213579177856445\n",
      "Iteration=13820 took: 1:12:52.128321, loss: 2.6023335456848145\n",
      "Iteration=13840 took: 1:12:58.452733, loss: 3.7756168842315674\n",
      "Iteration=13860 took: 1:13:04.811276, loss: 2.153475522994995\n",
      "Iteration=13880 took: 1:13:11.442445, loss: 5.7326202392578125\n",
      "Iteration=13900 took: 1:13:17.543115, loss: 1.9502869844436646\n",
      "Iteration=13920 took: 1:13:23.798119, loss: 6.978771686553955\n",
      "Iteration=13940 took: 1:13:30.227154, loss: 8.427765846252441\n",
      "Iteration=13960 took: 1:13:36.434829, loss: 3.0933759212493896\n",
      "Iteration=13980 took: 1:13:42.740080, loss: 3.6040146350860596\n",
      "Iteration=14000 took: 1:13:48.946445, loss: 5.637789249420166\n",
      "Iteration=14020 took: 1:13:55.221165, loss: 5.17252254486084\n",
      "Iteration=14040 took: 1:14:01.515297, loss: 4.616487979888916\n",
      "Iteration=14060 took: 1:14:08.166115, loss: 3.927882194519043\n",
      "Iteration=14080 took: 1:14:14.390302, loss: 4.925619602203369\n",
      "Iteration=14100 took: 1:14:20.529198, loss: 2.881685495376587\n",
      "Iteration=14120 took: 1:14:26.791343, loss: 7.153721332550049\n",
      "Iteration=14140 took: 1:14:33.103913, loss: 6.54958963394165\n",
      "Iteration=14160 took: 1:14:39.375134, loss: 3.506385326385498\n",
      "Iteration=14180 took: 1:14:45.642453, loss: 6.190288066864014\n",
      "Iteration=14200 took: 1:14:51.943962, loss: 4.906088829040527\n",
      "Iteration=14220 took: 1:14:58.149160, loss: 5.9041595458984375\n",
      "Iteration=14240 took: 1:15:04.084707, loss: 3.5671651363372803\n",
      "Iteration=14260 took: 1:15:10.311406, loss: 2.8398866653442383\n",
      "Iteration=14280 took: 1:15:16.772114, loss: 5.186373233795166\n",
      "Iteration=14300 took: 1:15:23.025628, loss: 4.725956439971924\n",
      "Iteration=14320 took: 1:15:29.263535, loss: 4.564451217651367\n",
      "Iteration=14340 took: 1:15:35.578936, loss: 5.232623100280762\n",
      "Iteration=14360 took: 1:15:41.798568, loss: 4.958093643188477\n",
      "Iteration=14380 took: 1:15:47.801882, loss: 7.103550434112549\n",
      "Iteration=14400 took: 1:15:53.759866, loss: 3.6656761169433594\n",
      "Iteration=14420 took: 1:15:59.863761, loss: 5.837585926055908\n",
      "Iteration=14440 took: 1:16:06.314788, loss: 3.0702738761901855\n",
      "Iteration=14460 took: 1:16:12.723227, loss: 3.892063617706299\n",
      "Iteration=14480 took: 1:16:19.233389, loss: 5.193674087524414\n",
      "Iteration=14500 took: 1:16:25.330712, loss: 5.343369960784912\n",
      "Iteration=14520 took: 1:16:31.421512, loss: 7.819511413574219\n",
      "Iteration=14540 took: 1:16:37.528484, loss: 6.103489398956299\n",
      "Iteration=14560 took: 1:16:43.715073, loss: 7.448387622833252\n",
      "Iteration=14580 took: 1:16:50.086853, loss: 3.7773125171661377\n",
      "Iteration=14600 took: 1:16:55.904510, loss: 4.908980846405029\n",
      "Iteration=14620 took: 1:17:02.298244, loss: 5.673036098480225\n",
      "Iteration=14640 took: 1:17:08.810752, loss: 5.68666934967041\n",
      "Iteration=14660 took: 1:17:14.806581, loss: 7.794177532196045\n",
      "Iteration=14680 took: 1:17:21.027046, loss: 5.703725814819336\n",
      "Iteration=14700 took: 1:17:27.455614, loss: 6.849755764007568\n",
      "Iteration=14720 took: 1:17:34.003378, loss: 7.054380893707275\n",
      "Iteration=14740 took: 1:17:40.402496, loss: 4.318379878997803\n",
      "Iteration=14760 took: 1:17:46.606905, loss: 7.8362555503845215\n",
      "Iteration=14780 took: 1:17:52.861150, loss: 5.728001117706299\n",
      "Iteration=14800 took: 1:17:58.736196, loss: 7.48832893371582\n",
      "Iteration=14820 took: 1:18:05.194214, loss: 8.806061744689941\n",
      "Iteration=14840 took: 1:18:11.507873, loss: 3.083251714706421\n",
      "Iteration=14860 took: 1:18:17.616218, loss: 5.4425950050354\n",
      "Iteration=14880 took: 1:18:23.829017, loss: 2.9623754024505615\n",
      "Iteration=14900 took: 1:18:30.068394, loss: 5.493224143981934\n",
      "Iteration=14920 took: 1:18:36.149207, loss: 4.262482166290283\n",
      "Iteration=14940 took: 1:18:42.453040, loss: 3.753986358642578\n",
      "Iteration=14960 took: 1:18:48.894566, loss: 4.948065757751465\n",
      "Iteration=14980 took: 1:18:54.939387, loss: 7.530317783355713\n",
      "Iteration=15000 took: 1:19:01.055126, loss: 8.079253196716309\n",
      "Iteration=15020 took: 1:19:07.317807, loss: 2.22895884513855\n",
      "Iteration=15040 took: 1:19:13.847248, loss: 5.8002166748046875\n",
      "Iteration=15060 took: 1:19:20.269219, loss: 7.377470016479492\n",
      "Iteration=15080 took: 1:19:26.600363, loss: 4.124927520751953\n",
      "Iteration=15100 took: 1:19:33.049022, loss: 6.3661298751831055\n",
      "Iteration=15120 took: 1:19:39.395235, loss: 8.73058795928955\n",
      "Iteration=15140 took: 1:19:45.852229, loss: 2.480699062347412\n",
      "Iteration=15160 took: 1:19:51.655642, loss: 4.084848880767822\n",
      "Iteration=15180 took: 1:19:57.698704, loss: 3.1631979942321777\n",
      "Iteration=15200 took: 1:20:04.148909, loss: 4.327832221984863\n",
      "Iteration=15220 took: 1:20:10.279327, loss: 3.8095953464508057\n",
      "Iteration=15240 took: 1:20:16.757369, loss: 5.828646183013916\n",
      "Iteration=15260 took: 1:20:22.991360, loss: 4.001672267913818\n",
      "Iteration=15280 took: 1:20:28.974986, loss: 2.1151320934295654\n",
      "Iteration=15300 took: 1:20:34.952173, loss: 2.85634446144104\n",
      "Iteration=15320 took: 1:20:41.212937, loss: 5.259806156158447\n",
      "Iteration=15340 took: 1:20:47.187377, loss: 4.043121814727783\n",
      "Iteration=15360 took: 1:20:53.314780, loss: 3.5807759761810303\n",
      "Iteration=15380 took: 1:20:59.460191, loss: 7.163947582244873\n",
      "Iteration=15400 took: 1:21:05.803214, loss: 4.774907112121582\n",
      "Iteration=15420 took: 1:21:12.151746, loss: 4.747379779815674\n",
      "Iteration=15440 took: 1:21:18.346601, loss: 7.594775199890137\n",
      "Iteration=15460 took: 1:21:24.588678, loss: 3.4683289527893066\n",
      "Iteration=15480 took: 1:21:31.047791, loss: 2.874551296234131\n",
      "Iteration=15500 took: 1:21:37.216213, loss: 3.361206531524658\n",
      "Iteration=15520 took: 1:21:43.677577, loss: 6.145510196685791\n",
      "Iteration=15540 took: 1:21:49.903720, loss: 5.5667405128479\n",
      "Iteration=15560 took: 1:21:56.374625, loss: 8.55705738067627\n",
      "Iteration=15580 took: 1:22:02.446219, loss: 5.855399131774902\n",
      "Iteration=15600 took: 1:22:08.792222, loss: 3.9288055896759033\n",
      "Iteration=15620 took: 1:22:15.105414, loss: 4.980006217956543\n",
      "Iteration=15640 took: 1:22:21.295967, loss: 2.3684756755828857\n",
      "Iteration=15660 took: 1:22:27.562228, loss: 3.813598394393921\n",
      "Iteration=15680 took: 1:22:33.764377, loss: 2.7120814323425293\n",
      "Iteration=15700 took: 1:22:39.789786, loss: 2.5417184829711914\n",
      "Iteration=15720 took: 1:22:46.076210, loss: 3.9008712768554688\n",
      "Iteration=15740 took: 1:22:52.436124, loss: 3.693591356277466\n",
      "Iteration=15760 took: 1:22:58.533056, loss: 4.992069721221924\n",
      "Iteration=15780 took: 1:23:04.961661, loss: 4.932067394256592\n",
      "Iteration=15800 took: 1:23:11.483146, loss: 2.6784210205078125\n",
      "Iteration=15820 took: 1:23:17.582790, loss: 8.142375946044922\n",
      "Iteration=15840 took: 1:23:23.963404, loss: 3.411936044692993\n",
      "Iteration=15860 took: 1:23:30.240743, loss: 3.5541348457336426\n",
      "Iteration=15880 took: 1:23:36.557817, loss: 6.759500026702881\n",
      "Iteration=15900 took: 1:23:42.892406, loss: 2.9811713695526123\n",
      "Iteration=15920 took: 1:23:48.736113, loss: 2.165959358215332\n",
      "Iteration=15940 took: 1:23:54.919267, loss: 3.857466459274292\n",
      "Iteration=15960 took: 1:24:01.439525, loss: 4.014528751373291\n",
      "Iteration=15980 took: 1:24:07.705580, loss: 6.853638648986816\n",
      "Iteration=16000 took: 1:24:14.230999, loss: 3.3739044666290283\n",
      "Iteration=16020 took: 1:24:20.364740, loss: 5.3554487228393555\n",
      "Iteration=16040 took: 1:24:26.659924, loss: 2.934828281402588\n",
      "Iteration=16060 took: 1:24:32.945823, loss: 5.118732929229736\n",
      "Iteration=16080 took: 1:24:39.461657, loss: 4.816324234008789\n",
      "Iteration=16100 took: 1:24:45.884513, loss: 5.969359874725342\n",
      "Iteration=16120 took: 1:24:52.287158, loss: 4.405694484710693\n",
      "Iteration=16140 took: 1:24:58.527946, loss: 4.011502742767334\n",
      "Iteration=16160 took: 1:25:04.959977, loss: 5.022392749786377\n",
      "Iteration=16180 took: 1:25:11.033418, loss: 6.8087897300720215\n",
      "Iteration=16200 took: 1:25:17.358389, loss: 2.4502296447753906\n",
      "Iteration=16220 took: 1:25:23.594655, loss: 5.754849433898926\n",
      "Iteration=16240 took: 1:25:30.024023, loss: 3.9321138858795166\n",
      "Iteration=16260 took: 1:25:36.386319, loss: 5.542608261108398\n",
      "Iteration=16280 took: 1:25:42.656481, loss: 3.705549478530884\n",
      "Iteration=16300 took: 1:25:48.956612, loss: 1.7798497676849365\n",
      "Iteration=16320 took: 1:25:55.264146, loss: 6.02618932723999\n",
      "Iteration=16340 took: 1:26:01.556650, loss: 3.6597495079040527\n",
      "Iteration=16360 took: 1:26:07.718951, loss: 3.8026814460754395\n",
      "Iteration=16380 took: 1:26:14.019419, loss: 5.103367328643799\n",
      "Iteration=16400 took: 1:26:20.674699, loss: 4.145577907562256\n",
      "Iteration=16420 took: 1:26:26.899562, loss: 3.030561685562134\n",
      "Iteration=16440 took: 1:26:32.774982, loss: 4.975057601928711\n",
      "Iteration=16460 took: 1:26:39.181734, loss: 6.067573070526123\n",
      "Iteration=16480 took: 1:26:45.495891, loss: 3.108999490737915\n",
      "Iteration=16500 took: 1:26:51.623516, loss: 2.4579176902770996\n",
      "Iteration=16520 took: 1:26:57.847351, loss: 6.937713623046875\n",
      "Iteration=16540 took: 1:27:04.384206, loss: 5.734139919281006\n",
      "Iteration=16560 took: 1:27:10.484835, loss: 3.080733060836792\n",
      "Iteration=16580 took: 1:27:16.554537, loss: 3.3821001052856445\n",
      "Iteration=16600 took: 1:27:23.060709, loss: 4.317355632781982\n",
      "Iteration=16620 took: 1:27:29.179460, loss: 6.992141246795654\n",
      "Iteration=16640 took: 1:27:35.291464, loss: 6.337496757507324\n",
      "Iteration=16660 took: 1:27:41.524973, loss: 5.938105583190918\n",
      "Iteration=16680 took: 1:27:47.686910, loss: 4.99839973449707\n",
      "Iteration=16700 took: 1:27:53.919598, loss: 8.14511775970459\n",
      "Iteration=16720 took: 1:28:00.062080, loss: 6.922292232513428\n",
      "Iteration=16740 took: 1:28:06.545823, loss: 4.705938816070557\n",
      "Iteration=16760 took: 1:28:12.731030, loss: 3.552609920501709\n",
      "Iteration=16780 took: 1:28:19.269880, loss: 6.2208147048950195\n",
      "Iteration=16800 took: 1:28:25.600186, loss: 4.823069095611572\n",
      "Iteration=16820 took: 1:28:31.745638, loss: 4.981015205383301\n",
      "Iteration=16840 took: 1:28:38.116247, loss: 4.5616254806518555\n",
      "Iteration=16860 took: 1:28:44.436843, loss: 3.671884775161743\n",
      "Iteration=16880 took: 1:28:50.690174, loss: 3.9860305786132812\n",
      "Iteration=16900 took: 1:28:56.950449, loss: 5.325414657592773\n",
      "Iteration=16920 took: 1:29:03.082964, loss: 7.982581615447998\n",
      "Iteration=16940 took: 1:29:09.378709, loss: 5.392107963562012\n",
      "Iteration=16960 took: 1:29:15.694316, loss: 1.6389302015304565\n",
      "Iteration=16980 took: 1:29:22.064212, loss: 4.1983842849731445\n",
      "Iteration=17000 took: 1:29:28.268171, loss: 4.388846397399902\n",
      "Iteration=17020 took: 1:29:34.689839, loss: 1.860429048538208\n",
      "Iteration=17040 took: 1:29:40.760825, loss: 2.0452160835266113\n",
      "Iteration=17060 took: 1:29:47.147516, loss: 4.704235553741455\n",
      "Iteration=17080 took: 1:29:52.986220, loss: 4.036625862121582\n",
      "Iteration=17100 took: 1:29:59.413640, loss: 4.1445817947387695\n",
      "Iteration=17120 took: 1:30:05.690991, loss: 4.283778667449951\n",
      "Iteration=17140 took: 1:30:11.823858, loss: 2.784841299057007\n",
      "Iteration=17160 took: 1:30:18.272404, loss: 3.582392454147339\n",
      "Iteration=17180 took: 1:30:24.559269, loss: 4.773017406463623\n",
      "Iteration=17200 took: 1:30:30.655813, loss: 3.4764158725738525\n",
      "Iteration=17220 took: 1:30:37.206585, loss: 6.1776604652404785\n",
      "Iteration=17240 took: 1:30:43.553844, loss: 2.61177659034729\n",
      "Iteration=17260 took: 1:30:49.765874, loss: 4.902029514312744\n",
      "Iteration=17280 took: 1:30:55.933961, loss: 3.774463176727295\n",
      "Iteration=17300 took: 1:31:02.163496, loss: 4.725537300109863\n",
      "Iteration=17320 took: 1:31:08.357496, loss: 7.999980449676514\n",
      "Iteration=17340 took: 1:31:14.527242, loss: 4.73858642578125\n",
      "Iteration=17360 took: 1:31:20.542131, loss: 8.45240592956543\n",
      "Iteration=17380 took: 1:31:26.855353, loss: 8.986159324645996\n",
      "Iteration=17400 took: 1:31:32.811545, loss: 3.157057762145996\n",
      "Iteration=17420 took: 1:31:39.297069, loss: 3.2339277267456055\n",
      "Iteration=17440 took: 1:31:45.771482, loss: 6.338837146759033\n",
      "Iteration=17460 took: 1:31:52.091655, loss: 5.549564838409424\n",
      "Iteration=17480 took: 1:31:58.394713, loss: 2.3989386558532715\n",
      "Iteration=17500 took: 1:32:04.594261, loss: 1.8785498142242432\n",
      "Iteration=17520 took: 1:32:10.608161, loss: 7.020361423492432\n",
      "Iteration=17540 took: 1:32:16.703992, loss: 5.745815753936768\n",
      "Iteration=17560 took: 1:32:22.842011, loss: 3.691490888595581\n",
      "Iteration=17580 took: 1:32:29.110570, loss: 5.866269111633301\n",
      "Iteration=17600 took: 1:32:35.497409, loss: 8.287712097167969\n",
      "Iteration=17620 took: 1:32:41.686449, loss: 5.132288932800293\n",
      "Iteration=17640 took: 1:32:47.891782, loss: 3.1253395080566406\n",
      "Iteration=17660 took: 1:32:53.789406, loss: 7.503042697906494\n",
      "Iteration=17680 took: 1:32:59.912057, loss: 3.595176935195923\n",
      "Iteration=17700 took: 1:33:06.339982, loss: 2.696047067642212\n",
      "Iteration=17720 took: 1:33:12.554484, loss: 1.9400197267532349\n",
      "Iteration=17740 took: 1:33:18.842420, loss: 5.144730091094971\n",
      "Iteration=17760 took: 1:33:24.691021, loss: 2.9627249240875244\n",
      "Iteration=17780 took: 1:33:30.798294, loss: 4.444239139556885\n",
      "Iteration=17800 took: 1:33:37.110893, loss: 4.833693504333496\n",
      "Iteration=17820 took: 1:33:43.448695, loss: 4.697490215301514\n",
      "Iteration=17840 took: 1:33:49.664783, loss: 4.39566707611084\n",
      "Iteration=17860 took: 1:33:55.710673, loss: 4.86611270904541\n",
      "Iteration=17880 took: 1:34:01.633317, loss: 4.348484992980957\n",
      "Iteration=17900 took: 1:34:07.560079, loss: 2.179473400115967\n",
      "Iteration=17920 took: 1:34:13.699204, loss: 3.0027759075164795\n",
      "Iteration=17940 took: 1:34:20.041476, loss: 4.186327934265137\n",
      "Iteration=17960 took: 1:34:26.586882, loss: 5.133240699768066\n",
      "Iteration=17980 took: 1:34:32.715573, loss: 5.647922992706299\n",
      "Iteration=18000 took: 1:34:38.637775, loss: 4.8146748542785645\n",
      "Iteration=18020 took: 1:34:44.499368, loss: 3.5862176418304443\n",
      "Iteration=18040 took: 1:34:50.646887, loss: 4.653223037719727\n",
      "Iteration=18060 took: 1:34:57.157402, loss: 3.1101877689361572\n",
      "Iteration=18080 took: 1:35:03.324111, loss: 4.267126083374023\n",
      "Iteration=18100 took: 1:35:09.589379, loss: 2.62734317779541\n",
      "Iteration=18120 took: 1:35:15.575078, loss: 4.677578449249268\n",
      "Iteration=18140 took: 1:35:21.919681, loss: 4.737731456756592\n",
      "Iteration=18160 took: 1:35:28.147506, loss: 4.617104530334473\n",
      "Iteration=18180 took: 1:35:34.514826, loss: 2.853950023651123\n",
      "Iteration=18200 took: 1:35:40.505241, loss: 2.7143445014953613\n",
      "Iteration=18220 took: 1:35:46.713409, loss: 2.854062795639038\n",
      "Iteration=18240 took: 1:35:53.075148, loss: 6.563546180725098\n",
      "Iteration=18260 took: 1:35:59.405995, loss: 3.917790174484253\n",
      "Iteration=18280 took: 1:36:05.532928, loss: 1.9898489713668823\n",
      "Iteration=18300 took: 1:36:11.820184, loss: 3.0924744606018066\n",
      "Iteration=18320 took: 1:36:18.348780, loss: 7.643734931945801\n",
      "Iteration=18340 took: 1:36:24.426802, loss: 4.921832084655762\n",
      "Iteration=18360 took: 1:36:30.366105, loss: 4.505294322967529\n",
      "Iteration=18380 took: 1:36:36.631770, loss: 4.9083147048950195\n",
      "Iteration=18400 took: 1:36:42.648263, loss: 4.606403827667236\n",
      "Iteration=18420 took: 1:36:48.939712, loss: 5.583940029144287\n",
      "Iteration=18440 took: 1:36:55.449837, loss: 3.719000816345215\n",
      "Iteration=18460 took: 1:37:01.307219, loss: 2.551816701889038\n",
      "Iteration=18480 took: 1:37:07.533148, loss: 5.0683135986328125\n",
      "Iteration=18500 took: 1:37:13.525495, loss: 6.682966709136963\n",
      "Iteration=18520 took: 1:37:19.873063, loss: 3.5415024757385254\n",
      "Iteration=18540 took: 1:37:26.223354, loss: 2.6552393436431885\n",
      "Iteration=18560 took: 1:37:32.446210, loss: 2.231212615966797\n",
      "Iteration=18580 took: 1:37:38.719441, loss: 4.074599742889404\n",
      "Iteration=18600 took: 1:37:45.140420, loss: 2.640005350112915\n",
      "Iteration=18620 took: 1:37:51.549847, loss: 5.866302490234375\n",
      "Iteration=18640 took: 1:37:57.735428, loss: 3.0896899700164795\n",
      "Iteration=18660 took: 1:38:04.263527, loss: 4.272032260894775\n",
      "Iteration=18680 took: 1:38:10.712723, loss: 1.5716370344161987\n",
      "Iteration=18700 took: 1:38:16.868302, loss: 6.764576435089111\n",
      "Iteration=18720 took: 1:38:23.372577, loss: 3.612680673599243\n",
      "Iteration=18740 took: 1:38:29.498617, loss: 5.914882183074951\n",
      "Iteration=18760 took: 1:38:35.749130, loss: 6.74618673324585\n",
      "Iteration=18780 took: 1:38:42.072233, loss: 4.82979679107666\n",
      "Iteration=18800 took: 1:38:48.676279, loss: 6.6861772537231445\n",
      "Iteration=18820 took: 1:38:54.802522, loss: 2.5925557613372803\n",
      "Iteration=18840 took: 1:39:01.057021, loss: 5.11855411529541\n",
      "Iteration=18860 took: 1:39:07.400166, loss: 4.897649765014648\n",
      "Iteration=18880 took: 1:39:13.701348, loss: 2.1880133152008057\n",
      "Iteration=18900 took: 1:39:19.829978, loss: 7.876652717590332\n",
      "Iteration=18920 took: 1:39:25.771563, loss: 1.6279637813568115\n",
      "Iteration=18940 took: 1:39:31.746028, loss: 3.799638509750366\n",
      "Iteration=18960 took: 1:39:37.938185, loss: 4.466069221496582\n",
      "Iteration=18980 took: 1:39:44.128902, loss: 5.8085713386535645\n",
      "Iteration=19000 took: 1:39:50.525731, loss: 3.5067243576049805\n",
      "Iteration=19020 took: 1:39:56.760447, loss: 4.7407145500183105\n",
      "Iteration=19040 took: 1:40:02.881993, loss: 3.0354528427124023\n",
      "Iteration=19060 took: 1:40:08.895712, loss: 2.8020405769348145\n",
      "Iteration=19080 took: 1:40:15.125771, loss: 4.537933349609375\n",
      "Iteration=19100 took: 1:40:21.484558, loss: 4.847757339477539\n",
      "Iteration=19120 took: 1:40:27.803061, loss: 4.181881427764893\n",
      "Iteration=19140 took: 1:40:33.894199, loss: 3.510878086090088\n",
      "Iteration=19160 took: 1:40:39.910660, loss: 5.191447734832764\n",
      "Iteration=19180 took: 1:40:46.253541, loss: 2.6362690925598145\n",
      "Iteration=19200 took: 1:40:52.689765, loss: 5.578482151031494\n",
      "Iteration=19220 took: 1:40:58.934439, loss: 6.783732891082764\n",
      "Iteration=19240 took: 1:41:05.048605, loss: 5.048366069793701\n",
      "Iteration=19260 took: 1:41:11.267525, loss: 3.684161424636841\n",
      "Iteration=19280 took: 1:41:17.070067, loss: 6.41567325592041\n",
      "Iteration=19300 took: 1:41:23.345845, loss: 4.514007091522217\n",
      "Iteration=19320 took: 1:41:29.714187, loss: 5.634859561920166\n",
      "Iteration=19340 took: 1:41:35.948939, loss: 3.943497896194458\n",
      "Iteration=19360 took: 1:41:41.735843, loss: 7.0889787673950195\n",
      "Iteration=19380 took: 1:41:48.179598, loss: 4.019212245941162\n",
      "Iteration=19400 took: 1:41:54.060938, loss: 4.80027437210083\n",
      "Iteration=19420 took: 1:42:00.162107, loss: 3.560657262802124\n",
      "Iteration=19440 took: 1:42:06.420516, loss: 4.856380939483643\n",
      "Iteration=19460 took: 1:42:12.668236, loss: 3.869107961654663\n",
      "Iteration=19480 took: 1:42:18.421718, loss: 6.356240272521973\n",
      "Iteration=19500 took: 1:42:24.567262, loss: 7.678890705108643\n",
      "Iteration=19520 took: 1:42:30.786691, loss: 2.5504276752471924\n",
      "Iteration=19540 took: 1:42:36.866055, loss: 2.4284942150115967\n",
      "Iteration=19560 took: 1:42:43.151888, loss: 5.534480571746826\n",
      "Iteration=19580 took: 1:42:49.299918, loss: 4.131109237670898\n",
      "Iteration=19600 took: 1:42:55.766173, loss: 2.788156747817993\n",
      "Iteration=19620 took: 1:43:01.836015, loss: 2.790015697479248\n",
      "Iteration=19640 took: 1:43:08.242505, loss: 3.8743138313293457\n",
      "Iteration=19660 took: 1:43:14.627243, loss: 4.56858491897583\n",
      "Iteration=19680 took: 1:43:20.741788, loss: 5.077420234680176\n",
      "Iteration=19700 took: 1:43:26.873825, loss: 1.6240710020065308\n",
      "Iteration=19720 took: 1:43:33.386155, loss: 4.806081771850586\n",
      "Iteration=19740 took: 1:43:39.533214, loss: 4.561729907989502\n",
      "Iteration=19760 took: 1:43:45.875212, loss: 3.506432056427002\n",
      "Iteration=19780 took: 1:43:52.362031, loss: 5.9197564125061035\n",
      "Iteration=19800 took: 1:43:58.627259, loss: 5.085056781768799\n",
      "Iteration=19820 took: 1:44:04.918797, loss: 4.353457927703857\n",
      "Iteration=19840 took: 1:44:11.519443, loss: 3.5318803787231445\n",
      "Iteration=19860 took: 1:44:17.896129, loss: 4.763111591339111\n",
      "Iteration=19880 took: 1:44:24.262138, loss: 4.494785785675049\n",
      "Iteration=19900 took: 1:44:30.370501, loss: 5.25762414932251\n",
      "Iteration=19920 took: 1:44:36.696452, loss: 4.059101104736328\n",
      "Iteration=19940 took: 1:44:42.740134, loss: 4.991199970245361\n",
      "Iteration=19960 took: 1:44:48.808909, loss: 2.7638418674468994\n",
      "Iteration=19980 took: 1:44:55.182899, loss: 4.078810691833496\n",
      "Iteration=20000 took: 1:45:01.468068, loss: 4.712820053100586\n",
      "Train Successful - Model saved\n"
     ]
    }
   ],
   "source": [
    "import keras.optimizers\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model(model, json_path, weight_path):\n",
    "    json_string = model.to_json()\n",
    "    open(json_path, 'w').write(json_string)\n",
    "    dict = {}\n",
    "    i = 0\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        my_list = np.zeros(len(weights), dtype=np.object)\n",
    "        my_list[:] = weights\n",
    "        dict[str(i)] = my_list\n",
    "        i += 1\n",
    "    sio.savemat(weight_path, dict)\n",
    "\n",
    "def load_model(json_path):\n",
    "    model = model_from_json(open(json_path).read())\n",
    "    return model\n",
    "\n",
    "def load_batch_train(normal_path, normal_list, abnormal_path, abnormal_list):\n",
    "\n",
    "    batchsize=60\n",
    "    n_exp = int(batchsize/2)\n",
    "\n",
    "    num_normal = len(normal_list)\n",
    "    num_abnormal = len(abnormal_list)\n",
    "\n",
    "    abnor_list_idx = np.random.permutation(num_abnormal)\n",
    "    abnor_list = abnor_list_idx[:n_exp]\n",
    "    norm_list_idx = np.random.permutation(num_normal)\n",
    "    norm_list = norm_list_idx[:n_exp]\n",
    "\n",
    "    abnormal_feats = []\n",
    "    for video_idx in abnor_list:\n",
    "        video_path = os.path.join(abnormal_path, abnormal_list[video_idx])\n",
    "        with open(video_path, \"rb\") as f:\n",
    "            feats = np.load(f)\n",
    "        abnormal_feats.append(feats)\n",
    "\n",
    "    normal_feats = []\n",
    "    for video_idx in norm_list:\n",
    "        video_path = os.path.join(normal_path, normal_list[video_idx])\n",
    "        with open(video_path, \"rb\") as f:\n",
    "            feats = np.load(f)\n",
    "        normal_feats.append(feats)\n",
    "\n",
    "\n",
    "    all_feats = np.vstack((*abnormal_feats, *normal_feats))\n",
    "    all_labels = np.zeros(32*batchsize, dtype='uint8')\n",
    "\n",
    "    all_labels[:32*n_exp] = 1\n",
    "\n",
    "    return  all_feats, all_labels\n",
    "\n",
    "\n",
    "def custom_objective(y_true, y_pred):\n",
    "\n",
    "    y_true = K.reshape(y_true, [-1])\n",
    "    y_pred = K.reshape(y_pred, [-1])\n",
    "    n_seg = 32\n",
    "    nvid = 60\n",
    "    n_exp = int(nvid / 2)\n",
    "\n",
    "    max_scores_list = []\n",
    "    z_scores_list = []\n",
    "    temporal_constrains_list = []\n",
    "    sparsity_constrains_list = []\n",
    "\n",
    "    for i in range(0, n_exp, 1):\n",
    "\n",
    "        video_predictions = y_pred[i*n_seg:(i+1)*n_seg]\n",
    "\n",
    "        max_scores_list.append(K.max(video_predictions))\n",
    "        temporal_constrains_list.append(\n",
    "            K.sum(K.pow(video_predictions[1:] - video_predictions[:-1], 2))\n",
    "        )\n",
    "        sparsity_constrains_list.append(K.sum(video_predictions))\n",
    "\n",
    "    for j in range(n_exp, 2*n_exp, 1):\n",
    "\n",
    "        video_predictions = y_pred[j*n_seg:(j+1)*n_seg]\n",
    "        max_scores_list.append(K.max(video_predictions))\n",
    "\n",
    "    max_scores = K.stack(max_scores_list)\n",
    "    temporal_constrains = K.stack(temporal_constrains_list)\n",
    "    sparsity_constrains = K.stack(sparsity_constrains_list)\n",
    "\n",
    "    for ii in range(0, n_exp, 1):\n",
    "        max_z = K.maximum(1 - max_scores[:n_exp] + max_scores[n_exp+ii], 0)\n",
    "        z_scores_list.append(K.sum(max_z))\n",
    "\n",
    "    z_scores = K.stack(z_scores_list)\n",
    "    z = K.mean(z_scores)\n",
    "\n",
    "    return z + \\\n",
    "        0.00008*K.sum(temporal_constrains) + \\\n",
    "        0.00008*K.sum(sparsity_constrains)\n",
    "\n",
    "output_dir = \"/home/jupyter/project/\"\n",
    "normal_dir = \"/home/jupyter/project/processed_normal_train_features\"\n",
    "abnormal_dir = \"/home/jupyter/project/processed_abnormal_train_features\"\n",
    "\n",
    "normal_list = os.listdir(normal_dir)\n",
    "normal_list.sort()\n",
    "abnormal_list = os.listdir(abnormal_dir)\n",
    "abnormal_list.sort()\n",
    "\n",
    "weights_path = output_dir + 'weights_new.mat'\n",
    "\n",
    "model_path = output_dir + 'model.json'\n",
    "\n",
    "#Create Full connected Model\n",
    "model = classifier_model()\n",
    "\n",
    "adagrad = keras.optimizers.Adagrad(lr=0.001, epsilon=1e-08)\n",
    "model.compile(loss=custom_objective, optimizer=adagrad)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "       os.makedirs(output_dir)\n",
    "\n",
    "loss_graph =[]\n",
    "num_iters = 20000\n",
    "total_iterations = 0\n",
    "batchsize=60\n",
    "time_before = datetime.now()\n",
    "\n",
    "\n",
    "for it_num in range(num_iters):\n",
    "    inputs, targets = load_batch_train(\n",
    "        normal_dir, normal_list, abnormal_dir, abnormal_list\n",
    "    )\n",
    "    batch_loss = model.train_on_batch(inputs, targets)\n",
    "    loss_graph = np.hstack((loss_graph, batch_loss))\n",
    "    total_iterations += 1\n",
    "    if total_iterations % 20 == 0:\n",
    "        print (\"Iteration={} took: {}, loss: {}\".format(\n",
    "            total_iterations, datetime.now() - time_before, batch_loss)\n",
    "        )\n",
    "\n",
    "print(\"Train Successful - Model saved\")\n",
    "save_model(model, model_path, weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcb5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068934d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m68"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
